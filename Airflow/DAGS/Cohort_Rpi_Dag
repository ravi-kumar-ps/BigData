import os
import re
import json
import sys
import urllib2
import logging
from airflow import DAG
from airflow.operators.python_operator import (PythonOperator, BranchPythonOperator)
from airflow.operators.email_operator import EmailOperator
from airflow.operators.sensors import ExternalTaskSensor
from datetime import datetime, timedelta, time
import time
from collections import OrderedDict

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(__file__)), "")))
import rpi_utils as utils

log = logging.getLogger(__name__)


config = json.load(open(os.path.abspath(
    os.path.join(os.path.dirname(os.path.realpath(__file__)), os.pardir, os.pardir, "config/rpi/ranking_config.json"))),
    object_pairs_hook=OrderedDict)

dag = DAG('Cohort_Rpi_Dag',
          description='Cohort Rpi Signal Preparation Workflow',
          schedule_interval="30 10 * * *",
          start_date=datetime(2022, 05, 18), catchup=False, default_args=config["airflow_config"]["default_args"])

DAG_CONFIG_BUCKET_URL = "http://localhost:8800/buckets/search-spyder-dag-config"


def fetch_config_bucket(config_url):
    content = urllib2.urlopen(config_url).read()
    content_json = json.loads(content)
    return content_json["keys"]


def prepare_config(**kwargs):
    config = json.load(open(os.path.abspath(
        os.path.join(os.path.dirname(os.path.realpath(__file__)), os.pardir, os.pardir,
                     "config/rpi/ranking_config.json"))), object_pairs_hook=OrderedDict)
    temp_conf = str(config)

    datestring = kwargs["execution_date"].strftime("%Y-%m-%d")
    two_next_datestring = (kwargs["execution_date"]+timedelta(2)).strftime("%Y-%m-%d")
    bucket_data = fetch_config_bucket(DAG_CONFIG_BUCKET_URL)

    jar_name = bucket_data[config["RPI_config_Level_0"]["config_bucket_key_sparkjobs"]].split(":")[1].strip()
    config_bucket = bucket_data["prod_rpi_bucket"].strip()
    run_mode = bucket_data["fast_rpi_run_mode"].strip()

    temp_conf = temp_conf.replace("${config_bucket}", config_bucket)
    temp_conf = temp_conf.replace("${run_mode}", run_mode)
    temp_conf = temp_conf.replace("${date}", datestring)
    temp_conf = temp_conf.replace("${two_next_date}", two_next_datestring)
    temp_conf = temp_conf.replace("${numOfDays}", "29")

    index = 0
    for key in config.keys():
        if str(index) in key and index < 2:
            for k in config[key].keys():
                replace_string = "${" + k + "}"
                temp_conf = temp_conf.replace(replace_string, config[key][k])
                config = eval(temp_conf)
            index += 1
    kwargs["task_instance"].xcom_push(key="ranking_config", value=config)
    kwargs["task_instance"].xcom_push(key="datestring", value=datestring)
    kwargs["task_instance"].xcom_push(key="jar_name", value=jar_name)

prepare_run_task = PythonOperator(dag=dag, task_id='PrepareDAGRun', python_callable=prepare_config,
                                  provide_context=True)

dag_succeeded = EmailOperator(
    to='search-ranking-notifications@flipkart.com',
    task_id='DagSucceeded',
    provide_context=True,
    subject='Cohort Rpi Dag Succeeded - {{ti.xcom_pull(task_ids=\"PrepareDAGRun\", key=\"datestring\")}}',
    html_content="Cohort Rpi Dag Succeeded",
    dag=dag
)

# add a sensor here.

click_conversion_affluence_v1_tasks_sensor = ExternalTaskSensor(
    task_id='ClickConversionAffluenceV1TasksSensor',
    external_dag_id='Prod_Rpi_Input_Click_Conversion_Data_Preparation_Dag',
    external_task_id='AffluenceRankingDailyAggregation',
    execution_delta=timedelta(hours=1),
    timeout=5,
    dag=dag,
    retries=80,
    retry_delay=timedelta(minutes=5),
    email_on_retry=False
)

affluence_ranking_multiday_decay_aggregator = PythonOperator(
    task_id='AffluenceRankingMultiDayAggregation', dag=dag,
    provide_context=True, python_callable=utils.runSparkCommand,
    params={'key_name': 'affluence_ranking_multiday_decay_aggregator', 'dag_config_bucket_url': DAG_CONFIG_BUCKET_URL}
)

affluence_ranking_signal_preparation = PythonOperator(
    task_id='AffluenceRankingSignalPreparation', dag=dag,
    provide_context=True, python_callable=utils.runSparkCommand,
    params={'key_name': 'affluence_ranking_signal_preparation', 'dag_config_bucket_url': DAG_CONFIG_BUCKET_URL}
)

click_conversion_affluence_v2_tasks_sensor = ExternalTaskSensor(
    task_id='ClickConversionAffluenceV2TasksSensor',
    external_dag_id='Prod_Rpi_Input_Click_Conversion_Data_Preparation_Dag',
    external_task_id='AffluenceRankingV2DailyAggregation',
    execution_delta=timedelta(hours=1),
    timeout=5,
    dag=dag,
    retries=80,
    retry_delay=timedelta(minutes=5),
    email_on_retry=False
)

affluence_ranking_v2_multiday_decay_aggregator_v2 = PythonOperator(
    task_id='AffluenceRankingV2MultiDayAggregation', dag=dag,
    provide_context=True, python_callable=utils.runSparkCommand,
    params={'key_name': 'affluence_ranking_multiday_decay_aggregator_v2', 'dag_config_bucket_url': DAG_CONFIG_BUCKET_URL}
)

affluence_ranking_v2_signal_preparation_v2 = PythonOperator(
    task_id='AffluenceRankingV2SignalPreparation', dag=dag,
    provide_context=True, python_callable=utils.runSparkCommand,
    params={'key_name': 'affluence_ranking_signal_preparation_v2', 'dag_config_bucket_url': DAG_CONFIG_BUCKET_URL}
)

affluence_ranking_v2_axon_payload_preparation = PythonOperator(
    task_id='AffluenceRankingV2AxonPayloadPreparation', dag=dag,
    provide_context=True, python_callable=utils.runSparkCommand,
    params={'key_name': 'affluence_ranking_axon_payload_preparation_v2', 'dag_config_bucket_url': DAG_CONFIG_BUCKET_URL}
)

affluence_ranking_axon_debug_payload_preparation_v2 = PythonOperator(
    task_id='AffluenceRankingV2AxonDebugPayloadPreparation', dag=dag,
    provide_context=True, python_callable=utils.runSparkCommand,
    params={'key_name': 'affluence_ranking_axon_debug_payload_preparation_v2', 'dag_config_bucket_url': DAG_CONFIG_BUCKET_URL}
)


# Affluence Ranking Task Dependencies
prepare_run_task >> click_conversion_affluence_v1_tasks_sensor >> affluence_ranking_multiday_decay_aggregator >> affluence_ranking_signal_preparation >> dag_succeeded
prepare_run_task >> click_conversion_affluence_v2_tasks_sensor >> affluence_ranking_v2_multiday_decay_aggregator_v2 >> affluence_ranking_v2_signal_preparation_v2 >> affluence_ranking_v2_axon_payload_preparation >> affluence_ranking_axon_debug_payload_preparation_v2 >> dag_succeeded
